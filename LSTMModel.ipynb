{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import os\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import pickle\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Importing prompt and afterglow indexes using pickle\n",
    "with open('StartandFinish.pickle','rb') as f:\n",
    "    prompt_start, prompt_finish, afterglow_start, afterglow_finish = pickle.load(f)\n",
    "\n",
    "#Setting the directory\n",
    "directory = os.getcwd()\n",
    "desktop_dir = 'C:\\\\Users\\\\Alb\\\\Desktop'\n",
    "if directory == desktop_dir:\n",
    "    os.chdir('Raw Data')\n",
    "    \n",
    "#Listing files and setting column names\n",
    "files_list = os.listdir()\n",
    "col_names = ['Time', 'Time_err_p', 'Time_err_n', 'Fluence', 'Fluence_err_p', 'Fluence_err_n']\n",
    "\n",
    "#Fonksiyon tanımı\n",
    "def create_dataset(dataset,look_back=1):\n",
    "    dataX, dataY = [],[]\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back),0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i+look_back,0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "i=21 # For sGRB 051221A\n",
    "#Creating the dataframe\n",
    "dataframe = pandas.read_csv(files_list[i], sep='\\t', names=col_names, engine='python')\n",
    "dataframe = dataframe.drop(columns=['Time','Time_err_p', 'Time_err_n', 'Fluence_err_p', 'Fluence_err_n'])\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "\n",
    "#Extracting only the prompt and afterglow fluences in a single column\n",
    "prompt = dataset[prompt_start[i]:prompt_finish[i]]\n",
    "afterglow = dataset[afterglow_start[i]:afterglow_finish[i]]\n",
    "dataset = numpy.concatenate((prompt,afterglow))\n",
    "\n",
    "\n",
    "#Veri setinin normalize edilmesi\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#Train test split\n",
    "train_size = int(len(dataset)*0.2)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train),len(test))\n",
    "    \n",
    "\n",
    "#Matrislerin yeniden şekillendirilmesi\n",
    "look_back=1\n",
    "trainX, trainY = create_dataset(train,look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#Matrisi LSTM tarzına dönüştürme [sample, time step, feature]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "#LSTM modelinin hazırlanması\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1,look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=200,batch_size=1, verbose=2)\n",
    "\n",
    "#Tahminler ve hata hesabı\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset), label='Veri', color='black')\n",
    "plt.plot(trainPredictPlot, label='Train tahmini', color='blue')\n",
    "plt.plot(testPredictPlot, label='Test tahmini', color='red')\n",
    "plt.title('GRB 050502B, LSTM Tahmini')\n",
    "plt.xlabel('Veri noktası')\n",
    "plt.ylabel('Fluence (erg/cm^2/2)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
